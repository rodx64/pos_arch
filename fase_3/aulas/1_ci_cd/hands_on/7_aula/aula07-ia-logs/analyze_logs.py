#!/usr/bin/env python3
"""
ğŸ¤– Analisador de Logs com IA (versÃ£o LOCAL)

Este script usa Ollama rodando localmente para analisar
logs da aplicaÃ§Ã£o e identificar problemas.

Uso:
    python analyze_logs.py

PrÃ©-requisitos:
    1. Ollama instalado:
       - macOS: brew install ollama (ou https://ollama.com/download/mac)
       - Linux: curl -fsSL https://ollama.com/install.sh | sh
       - Windows: https://ollama.com/download/windows
    2. Modelo baixado: ollama pull llama3.2
    3. Ollama rodando: ollama serve
"""
import requests
import sys
from pathlib import Path


def read_logs(log_file: str = "logs/app.log") -> str:
    """
    LÃª o arquivo de logs.
    
    Args:
        log_file: Caminho para o arquivo de log
        
    Returns:
        ConteÃºdo do arquivo de log
    """
    log_path = Path(log_file)
    
    if not log_path.exists():
        print(f"âŒ Arquivo nÃ£o encontrado: {log_file}")
        sys.exit(1)
    
    return log_path.read_text()


def analyze_with_ollama(logs: str) -> str:
    """
    Envia logs para Ollama analisar.
    
    Args:
        logs: ConteÃºdo dos logs
        
    Returns:
        AnÃ¡lise da IA
    """
    
    prompt = f"""VocÃª Ã© um especialista em DevOps e SRE.

Analise os logs abaixo e forneÃ§a:

1. **ERROS CRÃTICOS**: Liste os erros mais graves encontrados
2. **PADRÃ•ES PREOCUPANTES**: Identifique sequÃªncias que indicam problemas
3. **CAUSA RAIZ PROVÃVEL**: O que provavelmente causou os problemas
4. **RECOMENDAÃ‡Ã•ES**: O que fazer para resolver e prevenir

Seja direto e objetivo. Use emojis para destacar severidade:
- ğŸ”´ CrÃ­tico
- ğŸŸ¡ AtenÃ§Ã£o
- ğŸŸ¢ OK

LOGS:
{logs}
"""

    try:
        # Timeout maior para modelos mais lentos (120s)
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "llama3.2",
                "prompt": prompt,
                "stream": False
            },
            timeout=120
        )
        response.raise_for_status()
        return response.json()["response"]
        
    except requests.exceptions.ConnectionError:
        print("âŒ Erro: Ollama nÃ£o estÃ¡ rodando!")
        print("")
        print("Para iniciar o Ollama:")
        print("  1. Abra outro terminal")
        print("  2. Execute: ollama serve")
        print("")
        sys.exit(1)
        
    except requests.exceptions.Timeout:
        print("âŒ Erro: Timeout na resposta do Ollama (>120s)")
        print("")
        print("PossÃ­veis soluÃ§Ãµes:")
        print("  1. Verifique se o Ollama estÃ¡ rodando: ollama serve")
        print("  2. Tente um modelo menor: ollama pull llama3.2:1b")
        print("  3. Reinicie o Ollama e tente novamente")
        print("")
        sys.exit(1)


def count_by_level(logs: str) -> dict:
    """
    Conta logs por nÃ­vel de severidade.
    
    Args:
        logs: ConteÃºdo dos logs
        
    Returns:
        DicionÃ¡rio com contagem por nÃ­vel
    """
    levels = {
        "INFO": 0,
        "WARN": 0,
        "ERROR": 0,
        "CRITICAL": 0
    }
    
    for line in logs.split("\n"):
        for level in levels:
            if f"[{level}]" in line:
                levels[level] += 1
                break
    
    return levels


def main():
    """FunÃ§Ã£o principal."""
    print("=" * 60)
    print("ğŸ¤– Analisador de Logs com IA (Ollama)")
    print("=" * 60)
    print("")
    
    # 1. Ler logs
    print("ğŸ“‚ Lendo arquivo de logs...")
    logs = read_logs()
    
    # 2. EstatÃ­sticas bÃ¡sicas
    levels = count_by_level(logs)
    total_lines = len(logs.strip().split("\n"))
    
    print(f"\nğŸ“Š EstatÃ­sticas:")
    print(f"   Total de linhas: {total_lines}")
    print(f"   ğŸŸ¢ INFO: {levels['INFO']}")
    print(f"   ğŸŸ¡ WARN: {levels['WARN']}")
    print(f"   ğŸ”´ ERROR: {levels['ERROR']}")
    print(f"   ğŸ’€ CRITICAL: {levels['CRITICAL']}")
    
    # 3. AnÃ¡lise com IA
    print("\nğŸ¤– Analisando com IA...")
    print("   â³ Aguarde, isso pode levar atÃ© 2 minutos...")
    print("-" * 60)
    
    analysis = analyze_with_ollama(logs)
    
    print("\nğŸ“‹ ANÃLISE DA IA:")
    print("=" * 60)
    print(analysis)
    print("=" * 60)


if __name__ == "__main__":
    main()
